{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright © 2021 LEADERG Inc. All rights reserved. Please keep it private. Publish to internet is not allowed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "num1 = 280\n",
    "num2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "data = pd.read_csv(\"data/stock/stock-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the data with volume = 0\n",
    "for i in range(len(data)):\n",
    "    if (data.volume[i] == '0'):\n",
    "        data = data.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = dict()\n",
    "for i in data.columns:\n",
    "    if i == \"date\":\n",
    "        processed_data[\"date\"] = data.date\n",
    "    else:\n",
    "        dataNoNa = data[data.volume!='0']\n",
    "        dataNoNa[i] = dataNoNa[i].replace(',', '', regex=True)\n",
    "        dataNumeric = pd.to_numeric(dataNoNa[i])\n",
    "        processed_data[i] = dataNumeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "for i in data.columns:\n",
    "    temp = pd.concat([temp, pd.DataFrame(processed_data[i])], axis=1)\n",
    "processed_data = temp\n",
    "\n",
    "data_org = processed_data.copy()\n",
    "\n",
    "temp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data augmentation\n",
    "for i in range(num1-1):\n",
    "    day = i+1\n",
    "    temp = data_org.loc[day:, ['volume', 'open', 'high', 'low', 'close']]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    processed_data = pd.concat([processed_data, temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate na\n",
    "if num1 > 1:\n",
    "    processed_data = processed_data[0:-(num1-1)]\n",
    "\n",
    "date_tmp = data_org['date'].iloc[(num1-1):]\n",
    "date_tmp = date_tmp.reset_index(drop=True)\n",
    "processed_data['date'] = date_tmp\n",
    "data_org_2 = data_org[(num1-1):]\n",
    "data_org_2 = data_org_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num2):\n",
    "    day = i+1\n",
    "    data_tmp = processed_data.copy()\n",
    "    temp = data_org_2['close'].iloc[day:]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    data_train = data_tmp[0:-day]\n",
    "    \n",
    "    if (day == 1):\n",
    "        predicted_colume = 'close after ' + str(day) + ' day'\n",
    "    else:\n",
    "        predicted_colume = 'close after ' + str(day) + ' days'\n",
    "    temp.name = predicted_colume\n",
    "    #outputPath = 'data/stock-' + str(num1*5) + 'to' + str(num2) + '-' + str(day) + '.csv'\n",
    "\t#outputPath = 'data/stock-' + str(num1*5) + 'to' + str(num2) + '-' + str(day) + '.csv'\n",
    "    #outputPath_validation = 'data/stock-' + str(num1*5) + 'to' + str(num2) + '-' + str(day) + '-validation.csv'\n",
    "    \n",
    "\n",
    "        \n",
    "    # concat new columns\n",
    "    data_train = pd.concat([data_train, temp], axis=1)\n",
    "    data_inference = pd.concat([data_tmp, temp], axis=1)\n",
    "    #print('temp[-1] =',temp[-1])\n",
    "    data_inference[predicted_colume] = data_inference[predicted_colume].fillna(data_org['close'].iloc[-1])\n",
    "    # validation proportion\n",
    "    #validation = int(data_tmp.shape[0]*num3)\n",
    "    #print('<', day, '> data_tmp.shape[0] = ', data_tmp.shape[0])\n",
    "    #print('validation = ', validation)\n",
    "    \n",
    "    \n",
    "    # save to csv\n",
    "    outputPath = 'data/stock/train_input.csv'\n",
    "    data_train.to_csv(outputPath, index=False)\n",
    "    outputPath = 'data/stock/inference_input.csv'\n",
    "    data_inference.to_csv(outputPath, index=False)\n",
    "\t\n",
    "    #if validation > 0:\n",
    "    #    data_tmp[0:-validation].to_csv(outputPath, index=False)\n",
    "    #    data_tmp[-validation:].to_csv(outputPath_validation, index=False)\n",
    "    #else:\n",
    "    #    data_tmp.to_csv(outputPath, index=False)\n",
    "\n",
    "print('準備完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
